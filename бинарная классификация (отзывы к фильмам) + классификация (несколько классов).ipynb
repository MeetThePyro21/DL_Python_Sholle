{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data( num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, для классификации в две категории можно использовать функцию бинарной перекрестной энтропии, для классификации в не- сколько категорий — многозначной перекрестной энтропии, для задач регрессии — среднеквадратичной ошибки, для обучения на последовательностях — ассоциативной временной классификации (Connectionist Temporal Classification, CTC) и т. д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 .4 . Классификация отзывов к фильмам: пример бинарной классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])\n",
    "#Поскольку мы ограничили себя 10 000 наиболее употребительных слов, в наборе отсутствуют индексы больше 10 000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()]) \n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Нельзя передать списки целых чисел непосредственно в нейронную сеть. Поэтому мы должны преобразовать их в тензоры. Сделать это можно двумя способами:\n",
    "\n",
    "Привести все списки к одинаковой длине, преобразовать их в тензоры целых чисел с формой (образцы, индексы_слов) и затем передать их в первый слой сети, способный обрабатывать такие целочисленные тензоры (слой Embedding, о котором подробнее мы поговорим далее в этой книге).\n",
    "\n",
    "Выполнить прямое кодирование списков в векторы нулей и единиц. Это может означать, например, преобразование последовательности [3, 5] в 10 000-мерный вектор, все элементы которого содержат нули, кроме элементов с индексами 3 и 5, которые содержат единицы. Затем их можно передать в первый слой сети типа Dense, способный обрабатывать векторизованные данные с вещественными\n",
    "числами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование последовательностей целых чисел в бинарную матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000): \n",
    "    results = np.zeros((len(sequences), dimension)) #Создание матрицы с фор- мой (len(sequences), dimension)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. #Запись единицы в элемент с данным индексом\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data) #Векторизованные обучающие данные\n",
    "x_test = vectorize_sequences(test_data) #Векторизованные контрольные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам также нужно векторизовать метки, что делается очень просто:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32') \n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_labels[0]))\n",
    "print(type(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Конструирование сети"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Входные данные представлены векторами, а метки — скалярами (единицами и нулями): это самый простой набор данных, какой можно встретить. С задачами этого вида прекрасно справляются сети, организованные как простой стек полносвязных (Dense) слоев с операцией активации relu: Dense(16, activation='relu').\n",
    "\n",
    "Аргумент (16), передаваемый каждому слою Dense, — это число скрытых нейронов слоя. Скрытый нейрон (hidden unit) — это измерение в пространстве представлений слоя. Как рассказывалось в главе 2, каждый слой Dense с операцией активации relu реализует следующую цепочку операций с тензорами: output = relu(dot(W, input) + b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В отношении такого стека слоев Dense требуется принять два важных архитектурных решения:\n",
    "сколько слоев использовать;\n",
    "сколько скрытых нейронов выбрать для каждого слоя.\n",
    "\n",
    "В главе 4 вы познакомитесь с формальными принципами, помогающими сделать выбор. А пока вам остается только довериться мне в следующем выборе:\n",
    "\n",
    "два промежуточных слоя с 16 скрытыми нейронами в каждом;\n",
    "третий слой будет выводить скалярное значение — оценку направленности\n",
    "текущего отзыва."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Функция relu (rectified linear unit — блок линейной ректификации) использует- ся для преобразования отрицательных значений в ноль (рис. 3.4), а сигмоидная функция рассредоточивает произвольные значения по интервалу [0, 1], возвращая значения, которые можно интерпретировать как вероятность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Настройка оптимизатора\n",
    "# from keras import optimizers\n",
    "\n",
    "# model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Использование нестандартных функций потерь и метрик\n",
    "# from keras import losses\n",
    "# from keras import metrics\n",
    "\n",
    "# model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "#               loss=losses.binary_crossentropy,\n",
    "#               metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание проверочного набора \n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000] \n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Теперь проведем обучение модели в течение 20 эпох (выполнив 20 итераций по всем образцам в тензорах x_train и y_train) пакетами по 512 образцов. В то же время будем следить за потерями и точностью на 10 000 отложенных образцов. Для этого достаточно передать проверочные данные в аргументе validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 4s 287us/step - loss: 0.5182 - acc: 0.7865 - val_loss: 0.3944 - val_acc: 0.8662\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 106us/step - loss: 0.3149 - acc: 0.9015 - val_loss: 0.3119 - val_acc: 0.8839\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.2279 - acc: 0.9292 - val_loss: 0.2792 - val_acc: 0.8912\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.1818 - acc: 0.9425 - val_loss: 0.2805 - val_acc: 0.8864\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 127us/step - loss: 0.1487 - acc: 0.9532 - val_loss: 0.2799 - val_acc: 0.8879\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.1251 - acc: 0.9601 - val_loss: 0.2870 - val_acc: 0.8874\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 106us/step - loss: 0.1023 - acc: 0.9692 - val_loss: 0.3057 - val_acc: 0.8835\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 123us/step - loss: 0.0871 - acc: 0.9734 - val_loss: 0.3267 - val_acc: 0.8789\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 124us/step - loss: 0.0714 - acc: 0.9811 - val_loss: 0.3448 - val_acc: 0.8792\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.0619 - acc: 0.9826 - val_loss: 0.3663 - val_acc: 0.8813\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 107us/step - loss: 0.0486 - acc: 0.9889 - val_loss: 0.4106 - val_acc: 0.8756\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 124us/step - loss: 0.0414 - acc: 0.9907 - val_loss: 0.4248 - val_acc: 0.8750\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.0349 - acc: 0.9921 - val_loss: 0.4653 - val_acc: 0.8720\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 1s 94us/step - loss: 0.0279 - acc: 0.9946 - val_loss: 0.4983 - val_acc: 0.8679\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s 94us/step - loss: 0.0229 - acc: 0.9961 - val_loss: 0.5157 - val_acc: 0.8708\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.0188 - acc: 0.9973 - val_loss: 0.5469 - val_acc: 0.8704\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 1s 94us/step - loss: 0.0125 - acc: 0.9989 - val_loss: 0.5861 - val_acc: 0.8662\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s 94us/step - loss: 0.0114 - acc: 0.9989 - val_loss: 0.6277 - val_acc: 0.8637\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.0096 - acc: 0.9989 - val_loss: 0.6577 - val_acc: 0.8650\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.0051 - acc: 0.9999 - val_loss: 0.7088 - val_acc: 0.8645\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "# loss = history_dict['loss'] \n",
    "# val_loss = history_dict['val_loss']\n",
    "\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# #«bo» - «синяя точка»\n",
    "# plt.plot(epochs, loss_values, 'bo', label='Training loss') \n",
    "# plt.plot(epochs, val_loss_values, 'b', label='Validation loss') \n",
    "# plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss') \n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() #Очистить рисунок\n",
    "acc = history_dict['acc']\n",
    "val_acc= history_dict['val_acc']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc') \n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc') \n",
    "plt.title('Training and validation accuracy') \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Как видите, на этапе обучения потери снижаются с каждой эпохой, а точность растет. Именно такое поведение ожидается от оптимизации градиентным спу- ском: величина, которую вы пытаетесь минимизировать, должна становиться все меньше с каждой итерацией. Но это не относится к потерям и точности на этапе проверки: похоже, что они достигли пика в четвертую эпоху. \n",
    "\n",
    "Это пример того, о чем мы предупреждали выше: модель, показывающая хорошие результаты на обучающих данных, не обязательно будет показывать такие же хорошие результаты на данных, которые не видела прежде. Выражаясь точнее, в данном случае наблюдается переобучение: после второй эпохи произошла чрезмерная оптимизация на обучающих данных, и в результате получилось представление, характерное для обучающих данных, не обобщающее данные за пределами обу- чающего набора.\n",
    "\n",
    "В данном случае для предотвращения переобучения можно прекратить обучение после третьей эпохи. Вообще говоря, есть целый спектр приемов, ослабляющих эффект переобучения, которые мы рассмотрим в главе 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## А теперь обучим новую сеть с нуля в течение четырех эпох и затем оценим получившийся результат на контрольных данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 0.4757 - accuracy: 0.8187\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 0.2735 - accuracy: 0.9073\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.2051 - accuracy: 0.9278\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1724 - accuracy: 0.9400\n",
      "25000/25000 [==============================] - 5s 184us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=4,\n",
    "          batch_size=512)\n",
    "\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2911772852802277, 0.8841999769210815]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Это простейшее решение позволило достичь точности 88 %.\n",
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Использование обученной сети для предсказаний на новых данных\n",
    "\n",
    "После обучения сети ее можно использовать для решения практических задач. Например, попробуем предсказать вероятность того, что отзывы будут положи- тельными, с помощью метода predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19202387],\n",
       "       [0.9986292 ],\n",
       "       [0.8771146 ],\n",
       "       ...,\n",
       "       [0.10484046],\n",
       "       [0.06336246],\n",
       "       [0.63275194]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "сеть уверена в одних образцах (0,99 или выше или 0,01 или ниже), но не так уверена в других (0,6; 0,4)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Вот какие выводы вы должны сделать из этого примера:\n",
    "\n",
    "Обычно исходные данные приходится подвергать некоторой предварительной обработке, чтобы передать их в нейронную сеть в виде тензоров. Последовательности слов можно преобразовать в бинарные векторы, но существуют также другие варианты.\n",
    "\n",
    "Стек слоев Dense с функцией активации relu способен решать широкий круг задач (включая классификацию эмоциональной окраски), и вы, вероятно, чаще всего будете использовать именно эту комбинацию.\n",
    "\n",
    "В задаче бинарной классификации (с двумя выходными классами) в конце вашей нейросети должен находиться слой Dense с одним нейроном и функцией активации sigmoid: результатом работы сети должно быть скалярное значение в диапазоне между 0 и 1, представляющее собой вероятность.\n",
    "\n",
    "С таким скалярным результатом, получаемым с помощью сигмоидной функции, в задачах бинарной классификации следует использовать функцию потерь binary_crossentropy.\n",
    "\n",
    "В общем случае оптимизатор rmsprop является наиболее подходящим выбором для любого типа задач. Одной головной болью меньше для вас.\n",
    "\n",
    "По мере улучшения на обучающих данных нейронные сети рано или поздно начинают переобучаться, демонстрируя ухудшение результатов на данных, которые они прежде не видели. Поэтому всегда контролируйте качество работы сети на данных не из обучающего набора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 .5 . Классификация новостных лент: пример классификации в несколько классов\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Мы будем работать с набором данных Reuters — выборкой новостных лент и их тем, публиковавшихся агентством Reuters в 1986 году. Это простой набор данных, широко используемых для классификации текста. Существует 46 разных тем; не- которые темы более широко представлены, некоторые — менее, но для каждой из них в обучающем наборе имеется не менее 10 примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data( num_words=10000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "По аналогии с примером IMDB, аргумент num_words=10000 ограничивает данные 10 000 наиболее часто встречающимися словами.\n",
    "Всего у нас имеется 8982 обучающих и 2246 контрольных примеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "По аналогии с отзывами в базе данных IMDB, каждый пример — это список целых чисел (индексов слов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Вот как можно декодировать индексы в слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index. items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in\n",
    "    train_data[0]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Обратите внимание, что индексы смещены на 3, потому что индексы 0, 1 и 2 зарезервированы для слов «padding» (отступ), «start of sequence» (начало последовательности) и «unknown» (неизвестно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10996: 'mdbl',\n",
       " 16260: 'fawc',\n",
       " 12089: 'degussa',\n",
       " 8803: 'woods',\n",
       " 13796: 'hanging',\n",
       " 20672: 'localized',\n",
       " 20673: 'sation',\n",
       " 20675: 'chanthaburi',\n",
       " 10997: 'refunding',\n",
       " 8804: 'hermann',\n",
       " 20676: 'passsengers',\n",
       " 20677: 'stipulate',\n",
       " 8352: 'heublein',\n",
       " 20713: 'screaming',\n",
       " 16261: 'tcby',\n",
       " 185: 'four',\n",
       " 1642: 'grains',\n",
       " 20680: 'broiler',\n",
       " 12090: 'wooden',\n",
       " 1220: 'wednesday',\n",
       " 13797: 'highveld',\n",
       " 7593: 'duffour',\n",
       " 20681: '0053',\n",
       " 3914: 'elections',\n",
       " 2563: '270',\n",
       " 3551: '271',\n",
       " 5113: '272',\n",
       " 3552: '273',\n",
       " 3400: '274',\n",
       " 7975: 'rudman',\n",
       " 3401: '276',\n",
       " 3478: '277',\n",
       " 3632: '278',\n",
       " 4309: '279',\n",
       " 9381: 'dormancy',\n",
       " 7247: 'errors',\n",
       " 3086: 'deferred',\n",
       " 20683: 'sptnd',\n",
       " 8805: 'cooking',\n",
       " 20684: 'stratabit',\n",
       " 16262: 'designing',\n",
       " 20685: 'metalurgicos',\n",
       " 13798: 'databank',\n",
       " 20686: '300er',\n",
       " 20687: 'shocks',\n",
       " 7972: 'nawg',\n",
       " 20688: 'tnta',\n",
       " 20689: 'perforations',\n",
       " 2891: 'affiliates',\n",
       " 20690: '27p',\n",
       " 16263: 'ching',\n",
       " 595: 'china',\n",
       " 16264: 'wagyu',\n",
       " 3189: 'affiliated',\n",
       " 16265: 'chino',\n",
       " 16266: 'chinh',\n",
       " 20692: 'slickline',\n",
       " 13799: 'doldrums',\n",
       " 12092: 'kids',\n",
       " 3028: 'climbed',\n",
       " 6693: 'controversy',\n",
       " 20693: 'kidd',\n",
       " 12093: 'spotty',\n",
       " 12639: 'rebel',\n",
       " 9382: 'millimetres',\n",
       " 4007: 'golden',\n",
       " 5689: 'projection',\n",
       " 12094: 'stern',\n",
       " 7903: \"hudson's\",\n",
       " 10066: 'dna',\n",
       " 20695: 'dnc',\n",
       " 20696: 'hodler',\n",
       " 2394: 'lme',\n",
       " 20697: 'insolvancy',\n",
       " 13800: 'music',\n",
       " 1984: 'therefore',\n",
       " 10998: 'dns',\n",
       " 6959: 'distortions',\n",
       " 13801: 'thassos',\n",
       " 20698: 'populations',\n",
       " 8806: 'meteorologist',\n",
       " 43: 'loss',\n",
       " 9383: 'exco',\n",
       " 20813: 'adventist',\n",
       " 16267: 'murchison',\n",
       " 10999: 'locked',\n",
       " 13802: 'kampala',\n",
       " 20699: 'arndt',\n",
       " 1267: 'nakasone',\n",
       " 20700: 'steinweg',\n",
       " 3633: \"india's\",\n",
       " 3029: 'wang',\n",
       " 10067: 'wane',\n",
       " 13803: 'unjust',\n",
       " 13804: 'titanium',\n",
       " 850: 'want',\n",
       " 20701: 'pinto',\n",
       " 16268: \"institutes'\",\n",
       " 7973: 'absolute',\n",
       " 4677: 'travel',\n",
       " 6422: 'cutback',\n",
       " 16269: 'nazmi',\n",
       " 1858: 'modest',\n",
       " 16270: 'shopwell',\n",
       " 20702: 'sedi',\n",
       " 20703: 'adoped',\n",
       " 16271: 'tulis',\n",
       " 20704: '18th',\n",
       " 20705: \"wmc's\",\n",
       " 20706: 'menlo',\n",
       " 11000: 'reiners',\n",
       " 12095: 'farmlands',\n",
       " 20707: 'nonsensical',\n",
       " 20708: 'elisra',\n",
       " 2461: 'welcomed',\n",
       " 20709: 'peup',\n",
       " 16272: \"holiday's\",\n",
       " 20711: 'activating',\n",
       " 16273: 'avondale',\n",
       " 16274: 'interational',\n",
       " 20712: 'welcomes',\n",
       " 16275: 'fip',\n",
       " 11001: 'tailings',\n",
       " 4205: 'fit',\n",
       " 16276: 'lifeline',\n",
       " 1916: 'bringing',\n",
       " 4819: 'fix',\n",
       " 6164: '624',\n",
       " 12096: 'naturalite',\n",
       " 6165: 'wales',\n",
       " 8807: 'fin',\n",
       " 11129: 'fio',\n",
       " 20714: 'ceremenony',\n",
       " 20715: 'sovr',\n",
       " 20716: \"yeo's\",\n",
       " 1788: 'effects',\n",
       " 13805: 'sixteen',\n",
       " 8808: 'undeveloped',\n",
       " 13806: 'glutted',\n",
       " 20717: 'barton',\n",
       " 20718: 'froday',\n",
       " 10089: 'arrow',\n",
       " 11002: 'stabilises',\n",
       " 6960: 'allan',\n",
       " 20719: '374p',\n",
       " 3891: '393',\n",
       " 4008: '392',\n",
       " 4206: '391',\n",
       " 3079: '390',\n",
       " 4550: '397',\n",
       " 6166: '396',\n",
       " 6423: '395',\n",
       " 4207: '394',\n",
       " 6961: '399',\n",
       " 4208: '398',\n",
       " 7595: 'stabilised',\n",
       " 5114: 'smelters',\n",
       " 20720: 'oprah',\n",
       " 20721: 'orginially',\n",
       " 20722: \"tvx's\",\n",
       " 16278: 'ponomarev',\n",
       " 20723: 'enviroment',\n",
       " 20724: \"reeves'\",\n",
       " 8363: 'mason',\n",
       " 1670: 'encourage',\n",
       " 7596: 'adapt',\n",
       " 12776: 'abbott',\n",
       " 13808: 'stamping',\n",
       " 20726: 'colquiri',\n",
       " 11003: 'ambrit',\n",
       " 8353: 'strata',\n",
       " 4821: 'corrects',\n",
       " 11922: 'sandra',\n",
       " 859: 'estimate',\n",
       " 20727: 'universally',\n",
       " 20728: 'chlorine',\n",
       " 16279: 'competes',\n",
       " 10068: 'leiner',\n",
       " 8809: 'ministries',\n",
       " 8810: 'disturbed',\n",
       " 13809: 'competed',\n",
       " 8811: 'juergen',\n",
       " 13810: 'kfw',\n",
       " 11004: 'turben',\n",
       " 9384: 'reintroduced',\n",
       " 20729: 'maladies',\n",
       " 4101: 'chevron',\n",
       " 16280: 'lazere',\n",
       " 8812: 'antilles',\n",
       " 11907: 'dti',\n",
       " 9070: 'specially',\n",
       " 4678: 'bilzerian',\n",
       " 13811: 'bakelite',\n",
       " 20730: 'renovated',\n",
       " 568: 'service',\n",
       " 16281: 'payless',\n",
       " 20731: 'spiegler',\n",
       " 831: 'needed',\n",
       " 16282: 'wigglesworth',\n",
       " 6962: 'master',\n",
       " 13812: 'antonson',\n",
       " 20732: 'genesis',\n",
       " 13813: 'vismara',\n",
       " 20734: 'organically',\n",
       " 20735: \"accords'\",\n",
       " 5940: 'task',\n",
       " 7974: 'positively',\n",
       " 3479: 'feasibility',\n",
       " 6963: 'ahmed',\n",
       " 13814: \"suralco's\",\n",
       " 20736: 'awacs',\n",
       " 16283: 'idly',\n",
       " 20737: 'regulator',\n",
       " 12097: 'pseudorabies',\n",
       " 16284: 'staubli',\n",
       " 8813: 'nzi',\n",
       " 5115: 'feeling',\n",
       " 3127: '275',\n",
       " 20738: '6819',\n",
       " 16285: 'gorman',\n",
       " 8354: 'sustaining',\n",
       " 9385: 'spectrum',\n",
       " 20739: 'consenting',\n",
       " 12098: 'recapitalized',\n",
       " 11562: 'sailed',\n",
       " 7597: 'dozen',\n",
       " 1985: 'affairs',\n",
       " 2253: 'courier',\n",
       " 8355: 'kremlin',\n",
       " 895: 'shipments',\n",
       " 16286: \"aquino's\",\n",
       " 10070: 'committing',\n",
       " 5293: 'sugarcane',\n",
       " 9386: 'diminishing',\n",
       " 16287: 'vexing',\n",
       " 11005: 'simplify',\n",
       " 6167: 'mouth',\n",
       " 7248: 'steinhardt',\n",
       " 8814: 'conceded',\n",
       " 9387: 'bradford',\n",
       " 7976: 'singer',\n",
       " 20740: '5602',\n",
       " 13816: \"1987's\",\n",
       " 4950: 'tech',\n",
       " 6424: 'teck',\n",
       " 20741: 'majv',\n",
       " 666: 'saying',\n",
       " 16477: 'dickey',\n",
       " 20742: 'sweetner',\n",
       " 21149: 'teresa',\n",
       " 20743: 'ulcer',\n",
       " 13817: 'cheaply',\n",
       " 2361: 'thai',\n",
       " 6964: 'orleans',\n",
       " 16290: 'excavator',\n",
       " 6168: 'rico',\n",
       " 12099: 'lube',\n",
       " 13818: 'rick',\n",
       " 4679: 'rich',\n",
       " 13819: 'kerna',\n",
       " 950: 'rice',\n",
       " 4209: 'rica',\n",
       " 5503: 'plate',\n",
       " 16291: 'platt',\n",
       " 8356: 'altogether',\n",
       " 8815: 'jaguar',\n",
       " 20744: 'dynair',\n",
       " 8816: 'patch',\n",
       " 2892: 'ldp',\n",
       " 13820: 'boarded',\n",
       " 16292: 'precluding',\n",
       " 11006: 'clarified',\n",
       " 16293: 'sensitivity',\n",
       " 1511: 'alternative',\n",
       " 11007: 'clarifies',\n",
       " 5116: 'lots',\n",
       " 7598: 'irs',\n",
       " 20745: 'irv',\n",
       " 13821: 'iri',\n",
       " 13822: 'ira',\n",
       " 5690: 'timber',\n",
       " 20746: 'ire',\n",
       " 5219: 'discipline',\n",
       " 1937: 'extend',\n",
       " 3634: 'nature',\n",
       " 16295: \"amb's\",\n",
       " 16296: 'dunhill',\n",
       " 2142: 'extent',\n",
       " 20747: 'restrcitions',\n",
       " 2396: 'heating',\n",
       " 11008: \"mannesmann's\",\n",
       " 20748: 'outsanding',\n",
       " 20749: 'multimillions',\n",
       " 13824: 'sarcinelli',\n",
       " 6694: 'southeastern',\n",
       " 10071: 'eradicate',\n",
       " 9388: 'libyan',\n",
       " 20750: 'foreclosing',\n",
       " 12101: 'maclaine',\n",
       " 20751: 'fra',\n",
       " 353: 'union',\n",
       " 11009: 'frn',\n",
       " 386: 'much',\n",
       " 12102: 'fry',\n",
       " 20752: 'mothball',\n",
       " 10072: 'chlorazepate',\n",
       " 12103: 'dxns',\n",
       " 19981: 'toyko',\n",
       " 20753: 'spit',\n",
       " 16297: '007050',\n",
       " 16298: 'freehold',\n",
       " 13825: 'davy',\n",
       " 11010: 'dave',\n",
       " 12177: 'spie',\n",
       " 10117: 'aguayo',\n",
       " 12104: 'wildcat',\n",
       " 10069: 'fecs',\n",
       " 20754: 'kennan',\n",
       " 16299: 'intal',\n",
       " 9389: 'contingencies',\n",
       " 16551: 'professionally',\n",
       " 16300: 'microbiological',\n",
       " 20756: 'misconstrued',\n",
       " 409: 'k',\n",
       " 20757: 'securitiesd',\n",
       " 16301: 'deferring',\n",
       " 5941: 'kohl',\n",
       " 3030: 'conditioned',\n",
       " 20758: 'fnhb',\n",
       " 16302: \"october's\",\n",
       " 13954: 'memorial',\n",
       " 6965: 'democracies',\n",
       " 27520: 'conformed',\n",
       " 464: 'split',\n",
       " 12105: \"bond's\",\n",
       " 11112: 'thinly',\n",
       " 16515: 'dunkirk',\n",
       " 16303: 'cavanaugh',\n",
       " 13827: \"securities'\",\n",
       " 21345: 'marches',\n",
       " 16304: 'issam',\n",
       " 2020: 'workforce',\n",
       " 12106: 'meinert',\n",
       " 13828: 'boiler',\n",
       " 5294: \"bp's\",\n",
       " 16305: 'torpedoed',\n",
       " 20762: 'indidate',\n",
       " 13829: 'downwardly',\n",
       " 20763: 'viviez',\n",
       " 20764: 'vladiminovich',\n",
       " 16306: 'academic',\n",
       " 20765: 'architecural',\n",
       " 1117: 'corporate',\n",
       " 16307: 'appropriately',\n",
       " 20766: 'teicc',\n",
       " 20767: \"hanover's\",\n",
       " 8817: 'aristech',\n",
       " 20768: 'portrayed',\n",
       " 21383: 'raffineries',\n",
       " 20770: 'hai',\n",
       " 7599: 'hal',\n",
       " 13830: 'ham',\n",
       " 10073: 'han',\n",
       " 20771: 'e15b',\n",
       " 61: 'had',\n",
       " 20772: 'hay',\n",
       " 13831: 'botchwey',\n",
       " 10074: 'haq',\n",
       " 37: 'has',\n",
       " 13832: 'hat',\n",
       " 20773: 'hav',\n",
       " 20774: 'fortin',\n",
       " 8818: 'municipal',\n",
       " 20775: 'osman',\n",
       " 20776: 'fsical',\n",
       " 3480: 'elders',\n",
       " 12107: 'survival',\n",
       " 16308: 'unequivocally',\n",
       " 2519: 'objective',\n",
       " 6695: 'indicative',\n",
       " 10075: 'shadow',\n",
       " 21411: 'riskiness',\n",
       " 20778: 'positiive',\n",
       " 10076: \"american's\",\n",
       " 16309: 'alick',\n",
       " 16310: 'harima',\n",
       " 12108: 'alice',\n",
       " 20779: 'altschul',\n",
       " 16311: 'festivities',\n",
       " 20780: 'medecines',\n",
       " 2942: 'beneficial',\n",
       " 12109: 'yoweri',\n",
       " 13833: 'crowd',\n",
       " 9390: 'crowe',\n",
       " 3553: 'crown',\n",
       " 13679: 'topping',\n",
       " 8819: 'captive',\n",
       " 12110: 'billboard',\n",
       " 6169: 'fiduciary',\n",
       " 3402: 'bottom',\n",
       " 20782: 'plucked',\n",
       " 20783: 'locksmithing',\n",
       " 9391: 'ecopetrol',\n",
       " 24018: 'pipestone',\n",
       " 5505: \"growers'\",\n",
       " 20785: 'borrows',\n",
       " 16312: 'eduard',\n",
       " 13834: 'venpres',\n",
       " 16313: 'bamboo',\n",
       " 13835: 'foolish',\n",
       " 20786: 'uruguyan',\n",
       " 20787: 'officeholders',\n",
       " 20788: 'economiques',\n",
       " 16314: 'aden',\n",
       " 4822: 'maxwell',\n",
       " 4680: 'marshall',\n",
       " 16315: 'honeymoon',\n",
       " 16316: 'administer',\n",
       " 20790: 'shoots',\n",
       " 16317: 'rubbertech',\n",
       " 16318: 'johsen',\n",
       " 10077: 'reciprocity',\n",
       " 13836: 'fabric',\n",
       " 20791: 'suffice',\n",
       " 20792: 'spokemsan',\n",
       " 20793: \"sonora's\",\n",
       " 16319: '5865',\n",
       " 16320: \"systems'\",\n",
       " 20794: 'perfumes',\n",
       " 20795: 'halycon',\n",
       " 20796: 'nonvoting',\n",
       " 7250: 'safeguard',\n",
       " 21538: 'sawdust',\n",
       " 20797: \"else's\",\n",
       " 13837: 'arrays',\n",
       " 20798: 'aza',\n",
       " 20799: 'smasher',\n",
       " 12111: 'complications',\n",
       " 1813: 'pesos',\n",
       " 20800: 'relabelling',\n",
       " 3722: 'passenger',\n",
       " 12112: \"avon's\",\n",
       " 20801: 'megahertz',\n",
       " 10683: 'mirror',\n",
       " 8357: 'minas',\n",
       " 16322: 'bourdain',\n",
       " 20802: 'crownx',\n",
       " 6425: 'eventual',\n",
       " 1207: 'crowns',\n",
       " 1369: 'role',\n",
       " 20803: 'obliges',\n",
       " 16323: 'rolf',\n",
       " 13838: 'vegetative',\n",
       " 20804: 'rolm',\n",
       " 4419: 'roll',\n",
       " 2463: 'intend',\n",
       " 16324: 'palms',\n",
       " 19255: 'denys',\n",
       " 13839: 'transported',\n",
       " 20805: 'moresby',\n",
       " 16325: 'devon',\n",
       " 1351: 'intent',\n",
       " 20806: \"camco's\",\n",
       " 5942: 'variable',\n",
       " 20807: 'transporter',\n",
       " 16326: 'danske',\n",
       " 13840: 'friedhelm',\n",
       " 8358: 'hawker',\n",
       " 17774: \"sand's\",\n",
       " 20808: 'preseving',\n",
       " 12113: '80386',\n",
       " 16328: 'bnls',\n",
       " 19984: 'ordination',\n",
       " 11011: 'overturned',\n",
       " 16329: 'erred',\n",
       " 6696: 'cincinnati',\n",
       " 16710: 'corps',\n",
       " 20809: 'whoever',\n",
       " 16330: 'osp',\n",
       " 13841: 'osr',\n",
       " 12114: 'ost',\n",
       " 16331: 'chair',\n",
       " 5647: '690',\n",
       " 20810: 'grapples',\n",
       " 13842: 'megawatts',\n",
       " 20811: 'photocopiers',\n",
       " 20812: 'sconninx',\n",
       " 2274: 'circumstances',\n",
       " 13843: 'oversight',\n",
       " 20814: \"paradyne's\",\n",
       " 6363: '691',\n",
       " 20815: 'paychecks',\n",
       " 13844: \"stadelmann's\",\n",
       " 3241: 'choice',\n",
       " 11012: 'vastagh',\n",
       " 8820: 'embark',\n",
       " 9392: 'gloomy',\n",
       " 9393: 'stays',\n",
       " 4009: 'exact',\n",
       " 5117: 'minute',\n",
       " 11892: 'kittiwake',\n",
       " 20816: 'picul',\n",
       " 20817: 'skewed',\n",
       " 11013: 'cooke',\n",
       " 10078: 'defaults',\n",
       " 11014: 'reimpose',\n",
       " 9394: 'hindered',\n",
       " 20818: 'lengthened',\n",
       " 16333: 'chopping',\n",
       " 13845: 'mckiernan',\n",
       " 20819: 'collaspe',\n",
       " 7251: 'corazon',\n",
       " 7600: 'antwerp',\n",
       " 13846: 'abdullah',\n",
       " 13847: 'goldston',\n",
       " 442: '300',\n",
       " 20821: 'cassa',\n",
       " 20822: 'casse',\n",
       " 4081: '695',\n",
       " 2979: 'ground',\n",
       " 839: 'boost',\n",
       " 16334: 'azusa',\n",
       " 9395: 'drafted',\n",
       " 4823: '303',\n",
       " 13848: 'climbs',\n",
       " 7601: 'honour',\n",
       " 20823: 'vanderbilt',\n",
       " 3968: '305',\n",
       " 3031: 'address',\n",
       " 8821: 'dwindling',\n",
       " 7252: 'benson',\n",
       " 12115: 'enroll',\n",
       " 501: 'revenues',\n",
       " 12116: 'impacted',\n",
       " 20826: 'queue',\n",
       " 10079: 'accomplished',\n",
       " 7602: 'throughput',\n",
       " 9396: 'influx',\n",
       " 10080: 'stockbuilding',\n",
       " 20827: 'aproximates',\n",
       " 13849: 'petroleo',\n",
       " 16335: 'sistemas',\n",
       " 14053: 'feretti',\n",
       " 5943: 'opposes',\n",
       " 882: 'working',\n",
       " 20829: 'perished',\n",
       " 13850: 'oldham',\n",
       " 20830: '27000',\n",
       " 19245: 'optimize',\n",
       " 20832: 'vigour',\n",
       " 1580: 'opposed',\n",
       " 16336: 'liberalizing',\n",
       " 20833: 'wvz',\n",
       " 20834: 'dampness',\n",
       " 13851: 'approving',\n",
       " 13496: 'sierra',\n",
       " 20835: 'entrepot',\n",
       " 224: 'currency',\n",
       " 1499: 'originally',\n",
       " 20837: 'tindemans',\n",
       " 16337: 'valorem',\n",
       " 477: 'following',\n",
       " 20838: 'fossen',\n",
       " 11016: 'locke',\n",
       " 20839: 'employess',\n",
       " 12117: 'rotberg',\n",
       " 16338: 'parachute',\n",
       " 11017: 'locks',\n",
       " 12255: 'incremental',\n",
       " 16339: 'woolowrth',\n",
       " 20841: 'listens',\n",
       " 7253: 'litre',\n",
       " 3554: 'edouard',\n",
       " 1377: 'ounce',\n",
       " 20843: 'nicanor',\n",
       " 20844: 'sucocitrico',\n",
       " 16340: 'minicomputers',\n",
       " 16341: \"silva's\",\n",
       " 11018: 'restitutions',\n",
       " 16342: 'custer',\n",
       " 2590: '3rd',\n",
       " 10081: 'fueled',\n",
       " 20845: 'trydahl',\n",
       " 11019: 'aice',\n",
       " 12118: 'harmon',\n",
       " 10082: 'conscious',\n",
       " 20846: 'herbicidesand',\n",
       " 20847: 'subdivisions',\n",
       " 20848: \"veslefrikk's\",\n",
       " 11020: 'swollen',\n",
       " 7978: 'pulled',\n",
       " 20849: 'tilney',\n",
       " 203: 'years',\n",
       " 20850: 'structuring',\n",
       " 20851: 'episodes',\n",
       " 16343: 'sportscene',\n",
       " 16344: \"northair's\",\n",
       " 20852: 'jig',\n",
       " 20853: 'jin',\n",
       " 3403: 'jim',\n",
       " 8359: 'troubles',\n",
       " 13852: 'workforces',\n",
       " 2362: 'suspension',\n",
       " 3892: 'troubled',\n",
       " 16345: 'fondiaria',\n",
       " 6697: 'modestly',\n",
       " 12119: 'recipients',\n",
       " 7979: 'civilian',\n",
       " 13853: 'indigenous',\n",
       " 20854: 'overpowering',\n",
       " 1051: 'drilling',\n",
       " 16346: 'sorted',\n",
       " 16347: 'lichtenstein',\n",
       " 20855: 'bedevil',\n",
       " 20856: 'dispite',\n",
       " 16843: 'battleships',\n",
       " 4824: 'instability',\n",
       " 95: 'quarter',\n",
       " 20857: 'salado',\n",
       " 5692: 'honduras',\n",
       " 13855: \"chevron's\",\n",
       " 12273: \"lazere's\",\n",
       " 2660: 'receipt',\n",
       " 8360: 'sponsor',\n",
       " 4825: 'entering',\n",
       " 16349: \"kcbt's\",\n",
       " 19987: 'nowicki',\n",
       " 13856: 'salads',\n",
       " 16351: 'augar',\n",
       " 7980: '797',\n",
       " 7254: '796',\n",
       " 8361: '795',\n",
       " 5295: '794',\n",
       " 5118: '793',\n",
       " 6170: '792',\n",
       " 5296: '791',\n",
       " 4826: '790',\n",
       " 20858: \"nikko's\",\n",
       " 20859: 'unsaleable',\n",
       " 5720: '799',\n",
       " 5693: '798',\n",
       " 2143: 'seriously',\n",
       " 16352: 'trauma',\n",
       " 20860: 'tvbh',\n",
       " 20861: 'macedon',\n",
       " 21906: 'disintegrated',\n",
       " 21909: 'adddition',\n",
       " 2244: 'incentives',\n",
       " 5944: 'complicated',\n",
       " 20864: 'reevaluating',\n",
       " 21921: 'thatching',\n",
       " 7981: 'brasil',\n",
       " 20865: '79p',\n",
       " 4951: 'wrong',\n",
       " 8822: 'initiate',\n",
       " 16353: 'aboard',\n",
       " 7255: 'saving',\n",
       " 8823: 'spoken',\n",
       " 16364: 'parkinson',\n",
       " 65: 'one',\n",
       " 20867: 'ont',\n",
       " 7256: 'concert',\n",
       " 16354: \"boston's\",\n",
       " 13859: 'stifled',\n",
       " 4622: 'types',\n",
       " 20868: 'lingering',\n",
       " 16356: 'surges',\n",
       " 20869: 'hurdman',\n",
       " 16357: 'herds',\n",
       " 14114: 'absorbs',\n",
       " 4681: 'surged',\n",
       " 14211: 'dalkon',\n",
       " 13860: 'crossroads',\n",
       " 20870: 'shakeup',\n",
       " 20871: 'disasterous',\n",
       " 11021: 'illness',\n",
       " 3242: 'turned',\n",
       " 3801: 'locations',\n",
       " 12120: 'tyranite',\n",
       " 13861: 'minesweepers',\n",
       " 7257: 'turner',\n",
       " 20872: 'borough',\n",
       " 12358: 'underlines',\n",
       " 20873: \"bancorporation's\",\n",
       " 20874: 'fashionable',\n",
       " 20875: \"ae's\",\n",
       " 16358: 'dilutions',\n",
       " 9472: 'goodman',\n",
       " 10510: 'unlawfully',\n",
       " 16359: 'mayer',\n",
       " 16360: 'printer',\n",
       " 20877: 'offload',\n",
       " 13862: 'opposite',\n",
       " 738: 'buffer',\n",
       " 9398: 'printed',\n",
       " 16361: 'pequiven',\n",
       " 13863: 'panoche',\n",
       " 20878: 'knowingly',\n",
       " 16362: 'ecusta',\n",
       " 20879: 'thsl',\n",
       " 8825: 'phil',\n",
       " 13864: 'jitters',\n",
       " 16363: 'touche',\n",
       " 20881: 'jittery',\n",
       " 3291: 'friction',\n",
       " 16365: 'fecal',\n",
       " 22068: 'resurgance',\n",
       " 20882: 'heeding',\n",
       " 2363: 'soviets',\n",
       " 16366: 'imagined',\n",
       " 16367: 'transact',\n",
       " 20883: 'califoirnia',\n",
       " 9399: \"chrysler's\",\n",
       " 16368: 'respecitvely',\n",
       " 16369: 'presse',\n",
       " 10084: 'euromarket',\n",
       " 12121: 'guarded',\n",
       " 16371: 'satisfacotry',\n",
       " 20884: 'authroization',\n",
       " 20885: 'simplistic',\n",
       " 20886: 'monde',\n",
       " 4102: 'awaiting',\n",
       " 13865: 'recombinant',\n",
       " 20887: 'refinancement',\n",
       " 20888: 'comserv',\n",
       " 20889: 'kitakyushu',\n",
       " 16372: 'pima',\n",
       " 11022: 'basle',\n",
       " 20891: '6250',\n",
       " 16373: 'choudhury',\n",
       " 8826: 'vision',\n",
       " 20892: 'interruptible',\n",
       " 13866: 'weatherford',\n",
       " 7982: '832',\n",
       " 5694: '833',\n",
       " 4420: '830',\n",
       " 5119: '831',\n",
       " 5297: '836',\n",
       " 4553: '837',\n",
       " 6172: '834',\n",
       " 4952: '835',\n",
       " 22144: 'alarming',\n",
       " 5695: '838',\n",
       " 6173: '839',\n",
       " 20893: '524p',\n",
       " 20894: 'sponsorship',\n",
       " 12122: 'vendex',\n",
       " 20895: \"amsouth's\",\n",
       " 20896: 'kilometer',\n",
       " 10086: 'enjoys',\n",
       " 20897: 'illiberal',\n",
       " 6174: 'punta',\n",
       " 20898: 'punte',\n",
       " 10087: 'girozentrale',\n",
       " 20899: 'missstatements',\n",
       " 10088: 'marietta',\n",
       " 6175: 'awards',\n",
       " 3635: 'concentrated',\n",
       " 20900: '83p',\n",
       " 13867: 'developpement',\n",
       " 13868: 'rhodes',\n",
       " 5696: 'matheson',\n",
       " 20901: '1720',\n",
       " 20902: 'paring',\n",
       " 35: 's',\n",
       " 4953: 'concentrates',\n",
       " 16374: \"can's\",\n",
       " 22183: 'polysaturated',\n",
       " 20903: 'parini',\n",
       " 13869: 'baden',\n",
       " 20904: 'bader',\n",
       " 12123: 'buoyancy',\n",
       " 20905: 'erdem',\n",
       " 16375: 'properites',\n",
       " 20906: 'comparitive',\n",
       " 12124: 'practises',\n",
       " 20907: 'collides',\n",
       " 189: 'west',\n",
       " 20908: 'wess',\n",
       " 13870: 'collided',\n",
       " 20909: 'practised',\n",
       " 20910: \"amalgamated's\",\n",
       " 20911: 'motives',\n",
       " 1378: 'wants',\n",
       " 1273: 'formed',\n",
       " 20912: 'readings',\n",
       " 12125: 'geothermal',\n",
       " 7315: 'tightened',\n",
       " 11023: \"d'or\",\n",
       " 1109: 'former',\n",
       " 20913: 'venezulean',\n",
       " 19935: 'curd',\n",
       " 12126: 'squeezes',\n",
       " 1019: 'newspaper',\n",
       " 817: 'situation',\n",
       " 13871: 'ivey',\n",
       " 3636: 'engaged',\n",
       " 13872: 'dubious',\n",
       " 17061: 'cayacq',\n",
       " 20916: 'cobol',\n",
       " 20917: 'limping',\n",
       " 883: 'technology',\n",
       " 20919: 'koerner',\n",
       " 16376: 'debilitating',\n",
       " 7983: 'verified',\n",
       " 4010: 'otto',\n",
       " 20920: '7770',\n",
       " 16377: 'emulsions',\n",
       " 16378: \"onic's\",\n",
       " 9075: 'slate',\n",
       " 20921: 'wires',\n",
       " 5506: 'edged',\n",
       " 20922: 'assigns',\n",
       " 1341: 'singapore',\n",
       " 20923: 'deflate',\n",
       " 20924: \"strategy's\",\n",
       " 16379: 'walesa',\n",
       " 4554: 'advertisement',\n",
       " 20925: 'luyten',\n",
       " 20926: 'shrortly',\n",
       " 20927: 'corpoartion',\n",
       " 22290: 'preferance',\n",
       " 16380: 'tracking',\n",
       " 13874: 'sunnyvale',\n",
       " 20928: 'colorants',\n",
       " 16381: 'persistently',\n",
       " 16382: \"officers'\",\n",
       " 20929: \"his's\",\n",
       " 367: 'being',\n",
       " 7259: 'divestitures',\n",
       " 20930: 'steamer',\n",
       " 20931: 'rover',\n",
       " 8362: 'grounded',\n",
       " 16383: \"businessmen's\",\n",
       " 16384: 'cyanidation',\n",
       " 20932: 'overthrow',\n",
       " 20933: 'partnerhip',\n",
       " 16385: 'sumt',\n",
       " 8827: 'sums',\n",
       " 16386: 'oelmuehle',\n",
       " 16387: 'unveil',\n",
       " 13875: 'gestures',\n",
       " 20934: 'penta',\n",
       " 2544: 'traffic',\n",
       " 2428: 'preference',\n",
       " 20935: 'sumi',\n",
       " 166: 'world',\n",
       " 9400: 'postal',\n",
       " 16388: 'bced',\n",
       " 12128: 'dornbush',\n",
       " 14215: 'confine',\n",
       " 20936: '2555',\n",
       " 5945: \"zambia's\",\n",
       " 20937: 'superiority',\n",
       " 20938: 'militate',\n",
       " 2395: 'satisfactory',\n",
       " 20939: 'superintendent',\n",
       " 5946: 'tvx',\n",
       " 16389: 'tvt',\n",
       " 6698: 'magma',\n",
       " 20940: 'diving',\n",
       " 15548: 'tvb',\n",
       " 13876: 'seaman',\n",
       " 11025: 'matsunaga',\n",
       " 4827: '919',\n",
       " 5298: '918',\n",
       " 17070: 'refundable',\n",
       " 5947: '914',\n",
       " 7260: '917',\n",
       " 6699: '916',\n",
       " 5507: '911',\n",
       " 4828: '910',\n",
       " 10213: 'restoring',\n",
       " 4555: '912',\n",
       " 20942: 'squabble',\n",
       " 7261: 'retains',\n",
       " 20943: \"partner's\",\n",
       " 5300: 'leadership',\n",
       " 11026: 'graaf',\n",
       " 20944: 'spacelab',\n",
       " 1800: 'thailand',\n",
       " 9402: 'graan',\n",
       " 20945: 'exasperating',\n",
       " 12129: 'hartmarx',\n",
       " 16390: 'frights',\n",
       " 20946: 'niall',\n",
       " 11027: 'johnston',\n",
       " 16391: '91p',\n",
       " 16392: 'sensitively',\n",
       " 6016: 'porsche',\n",
       " 15494: 'prepares',\n",
       " 12130: 'lively',\n",
       " 10686: 'stoppages',\n",
       " 16394: \"associated's\",\n",
       " 12131: 'pivot',\n",
       " 1037: 'series',\n",
       " 24050: 'sese',\n",
       " 7604: 'bubble',\n",
       " 16395: 'trusses',\n",
       " 20949: 'interestate',\n",
       " 20950: 'continents',\n",
       " 20951: 'societal',\n",
       " 28: 'with',\n",
       " 6176: 'pull',\n",
       " 6700: 'rush',\n",
       " 6222: 'monopoly',\n",
       " 20953: 'operationally',\n",
       " 20954: 'dirty',\n",
       " 10090: 'abuses',\n",
       " 7262: 'prudhoe',\n",
       " 5949: 'pulp',\n",
       " 16396: 'rust',\n",
       " 20955: 'hellman',\n",
       " 20956: 'amdec',\n",
       " 16397: 'australasian',\n",
       " 13878: 'watches',\n",
       " 20957: 'hypertension',\n",
       " 20958: \"hemdale's\",\n",
       " 16398: 'formulation',\n",
       " 7605: 'watched',\n",
       " 20959: 'jargon',\n",
       " 13879: 'cream',\n",
       " 9404: 'ideally',\n",
       " 11028: 'ryavec',\n",
       " 20960: 'microoganisms',\n",
       " 13880: 'indemnify',\n",
       " 20961: 'wincenty',\n",
       " 20962: 'waving',\n",
       " 20963: \"multifood's\",\n",
       " 20964: 'midges',\n",
       " 11029: 'natalie',\n",
       " 13881: 'crosbie',\n",
       " 20965: 'posible',\n",
       " 13882: 'omnibus',\n",
       " 20966: 'assetsof',\n",
       " 13883: 'tricks',\n",
       " 16399: 'rs',\n",
       " 20967: 'kilogram',\n",
       " 25363: 'pruning',\n",
       " 13884: 'dyer',\n",
       " 20968: 'dyes',\n",
       " 20969: 'legislatures',\n",
       " 16400: 'scm',\n",
       " 9405: 'sci',\n",
       " 20970: 'riedel',\n",
       " 16401: 'ceramic',\n",
       " 6701: 'unitholders',\n",
       " 13885: 'scb',\n",
       " 20971: 'dn11',\n",
       " 20972: 'conditionality',\n",
       " 13807: \"stock's\",\n",
       " 20973: 'masland',\n",
       " 7606: 'causes',\n",
       " 10091: 'riots',\n",
       " 20974: 'norf',\n",
       " 9406: 'nord',\n",
       " 3893: 'midwest',\n",
       " 13886: 'tamils',\n",
       " 16402: 'ofthe',\n",
       " 3421: \"colombia's\",\n",
       " 11030: '24th',\n",
       " 20975: 'sant',\n",
       " 10092: 'moines',\n",
       " 22577: 'electrotechnical',\n",
       " 24534: 'proceeded',\n",
       " 20976: 'sanz',\n",
       " 13887: 'insufficiently',\n",
       " 20977: 'sang',\n",
       " 5950: 'sand',\n",
       " 16404: 'bracho',\n",
       " 805: 'small',\n",
       " 20978: 'workloads',\n",
       " 6702: 'sank',\n",
       " 20979: 'kemper',\n",
       " 16405: 'abbreviated',\n",
       " 13888: 'quicker',\n",
       " 3802: '199',\n",
       " 3243: '198',\n",
       " 2661: '195',\n",
       " 3080: '194',\n",
       " 4310: '197',\n",
       " 3894: '196',\n",
       " 2850: '191',\n",
       " 2199: '190',\n",
       " 3481: '193',\n",
       " 3350: '192',\n",
       " 582: 'past',\n",
       " 20980: 'fractionation',\n",
       " 20981: 'displays',\n",
       " 3081: 'pass',\n",
       " 202: 'investment',\n",
       " 27062: 'quals',\n",
       " 16406: 'quicken',\n",
       " 20983: \"centronic's\",\n",
       " 20984: 'menswear',\n",
       " 16407: 'clock',\n",
       " 20985: 'teape',\n",
       " 20986: 'teapa',\n",
       " 10093: 'prevailed',\n",
       " 9407: 'hebei',\n",
       " ...}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Метка, определяющая класс примера, — это целое число между 0 и 45 — индекс темы:\n",
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Для векторизации данных можно повторно использовать код из предыдущего примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension)) \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data) # Векторизованные обучающие данные\n",
    "x_test = vectorize_sequences(test_data) # Векторизованные контрольные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Векторизовать метки можно одним из двух способов: сохранить их в тензоре целых чисел или использовать прямое кодирование. Прямое кодирование (one - hot encoding) широко используется для форматирования категорий и также на- зывается кодированием категорий (categorical encoding). В данном случае прямое кодирование меток заключается в конструировании вектора с нулевыми элементами со значением 1 в элементе, индекс которого соответствует индексу метки. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1. \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels = to_one_hot(train_labels) \n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Следует отметить, что этот способ уже реализован в Keras, как мы видели в примере MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels) #Векторизованные обучающие данные\n",
    "one_hot_test_labels = to_categorical(test_labels) #Векторизованные контрольные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_test_labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Задача классификации по темам напоминает предыдущую задачу классификации отзывов: в обоих случаях мы пытаемся классифицировать короткие фрагменты текста. Но в данном случае количество выходных классов увеличилось с 2 до 46. Размерность выходного пространства теперь намного больше.\n",
    "\n",
    "В стеке слоев Dense, как в предыдущем примере, каждый слой имеет доступ только к информации, предоставленной предыдущим слоем. Если один слой отбросит какую-то информацию, важную для решения задачи классификации, последую- щие слои не смогут восстановить ее: каждый слой может стать узким местом для информации. В предыдущем примере мы использовали 16-мерные промежуточные слои, но 16-мерное пространство может оказаться слишком ограниченным для классификации на 46 разных классов: такие малоразмерные слои могут сыграть роль «бутылочного горлышка» для информации, не пропуская важные данные.\n",
    "\n",
    "По этой причине в данном примере мы будем использовать слои с большим коли- чеством измерений. Давайте выберем 64 нейрона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Сеть завершается слоем Dense с размером 46. Это означает, что для каждого входного образца сеть будет выводить 46-мерный вектор. Каждый элемент этого вектора (каждое измерение) представляет собой отдельный выходной класс.\n",
    "\n",
    "Последний слой использует функцию активации softmax. Мы уже видели этот шаблон в примере MNIST. Он означает, что сеть будет выводить распределение вероятностей по 46 разным классам — для каждого образца на входе сеть будет возвращать 46-мерный вектор, где output[i] — вероятность принадлежности образца классу i. Сумма 46 элементов всегда будет равна 1.\n",
    "\n",
    "Лучшим вариантом в данном случае является использование функции потерь categorical_crossentropy. Она определяет расстояние между распределениями вероятностей: в данном случае между распределением вероятности на выходе сети и истинным распределением меток. Минимизируя расстояние между этими двумя распределениями, мы учим сеть выводить результат, максимально близкий к истинным меткам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Для контроля точности модели создадим проверочный набор, выбрав 1000 образцов из набора обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 222us/step - loss: 2.5137 - accuracy: 0.5423 - val_loss: 1.6678 - val_accuracy: 0.6620\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 1.3937 - accuracy: 0.7102 - val_loss: 1.2853 - val_accuracy: 0.7120\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 1.0360 - accuracy: 0.7766 - val_loss: 1.1127 - val_accuracy: 0.7620\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.8135 - accuracy: 0.8252 - val_loss: 1.0130 - val_accuracy: 0.7770\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 171us/step - loss: 0.6486 - accuracy: 0.8614 - val_loss: 0.9617 - val_accuracy: 0.7900\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.5171 - accuracy: 0.8930 - val_loss: 0.9164 - val_accuracy: 0.7990\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.4181 - accuracy: 0.9132 - val_loss: 0.9081 - val_accuracy: 0.8140\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.3418 - accuracy: 0.9281 - val_loss: 0.9005 - val_accuracy: 0.8150\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.2880 - accuracy: 0.9377 - val_loss: 0.8781 - val_accuracy: 0.8150\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 132us/step - loss: 0.2414 - accuracy: 0.9451 - val_loss: 0.8917 - val_accuracy: 0.8140\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 103us/step - loss: 0.2082 - accuracy: 0.9493 - val_loss: 0.9058 - val_accuracy: 0.8200\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 0.1879 - accuracy: 0.9506 - val_loss: 0.9529 - val_accuracy: 0.8110\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 0.1614 - accuracy: 0.9543 - val_loss: 0.9635 - val_accuracy: 0.8090\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.1506 - accuracy: 0.9555 - val_loss: 0.9789 - val_accuracy: 0.8140\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.1381 - accuracy: 0.9554 - val_loss: 1.0085 - val_accuracy: 0.8130\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.1346 - accuracy: 0.9536 - val_loss: 1.0363 - val_accuracy: 0.8010\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.1262 - accuracy: 0.9553 - val_loss: 1.0663 - val_accuracy: 0.7970\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.1206 - accuracy: 0.9582 - val_loss: 1.0512 - val_accuracy: 0.8080\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 106us/step - loss: 0.1182 - accuracy: 0.9575 - val_loss: 1.0539 - val_accuracy: 0.8030\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.1139 - accuracy: 0.9568 - val_loss: 1.0549 - val_accuracy: 0.8090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train, \n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss') \n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() \n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Переобучение сети наступает в девятой эпохе. Давайте теперь обучим новую сеть до девятой эпохи и затем оценим получившийся результат на контрольных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 2.6166 - accuracy: 0.5345 - val_loss: 1.7332 - val_accuracy: 0.6340\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 1.4062 - accuracy: 0.7090 - val_loss: 1.2843 - val_accuracy: 0.7160\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 105us/step - loss: 1.0379 - accuracy: 0.7772 - val_loss: 1.1359 - val_accuracy: 0.7470\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.8137 - accuracy: 0.8270 - val_loss: 1.0139 - val_accuracy: 0.7680\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.6500 - accuracy: 0.8604 - val_loss: 0.9438 - val_accuracy: 0.7950\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 106us/step - loss: 0.5136 - accuracy: 0.8903 - val_loss: 0.9219 - val_accuracy: 0.8000\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.4158 - accuracy: 0.9110 - val_loss: 0.8881 - val_accuracy: 0.8000\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 0.3354 - accuracy: 0.9280 - val_loss: 0.9297 - val_accuracy: 0.7970\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 151us/step - loss: 0.2770 - accuracy: 0.9392 - val_loss: 0.8792 - val_accuracy: 0.8090\n",
      "2246/2246 [==============================] - 0s 160us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.980120306448117, 0.7849510312080383]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Теперь можно убедиться в том, что метод predict модели возвращает распределение вероятностей по всем 46 темам. Давайте сгенерируем предсказания для всех контрольных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сумма коэффициентов этого вектора равна 1:\n",
    "np.sum(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Наибольший элемент, элемент с наибольшей вероятностью, — это предсказанный класс:\n",
    "np.argmax(predictions[4])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Выше упоминалось, что метки также можно было бы преобразовать в тензор целых чисел, как показано ниже:\n",
    "\n",
    "y_train = np.array(train_labels) \n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "Единственное, что изменилось в данном случае, — функция потерь.\n",
    "В листинге 3.21 использовалась функция потерь categorical_crossentropy, предполагающая, что метки получены методом кодирования категорий. С целочисленными метками следует использовать функцию sparse_categorical_crossentropy:\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "              \n",
    "С математической точки зрения эта новая функция потерь равноценна функции categorical_crossentropy; ее отличает только интерфейс."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Выше уже говорилось, что не следует использовать слои, в которых значительно меньше 46 скрытых нейронов, потому что результат является 46-мерным. Теперь давайте посмотрим, что получится, если образуется узкое место для информации из-за промежуточных слоев с размерностями намного меньше 46, например четырехмерных.\n",
    "\n",
    "Теперь сеть показывает точность ~71 % — абсолютное падение составило 8 %. Это падение в основном обусловлено попыткой сжать большой объем информации (достаточной для восстановления гиперплоскостей, разделяющих 46 классов) в промежуточное пространство со слишком малой размерностью. Сети удалось вместить большую часть необходимой информации в эти четырехмерные пред- ставления, но не всю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 3.5139 - accuracy: 0.1156 - val_loss: 3.1754 - val_accuracy: 0.3550\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 2.8654 - accuracy: 0.3701 - val_loss: 2.6218 - val_accuracy: 0.3840\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 2.3772 - accuracy: 0.4168 - val_loss: 2.2926 - val_accuracy: 0.4220\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 2.0509 - accuracy: 0.4483 - val_loss: 2.0405 - val_accuracy: 0.4460\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 1.7366 - accuracy: 0.4980 - val_loss: 1.7409 - val_accuracy: 0.5850\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 1.4034 - accuracy: 0.6611 - val_loss: 1.5031 - val_accuracy: 0.6530\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 1.1981 - accuracy: 0.6828 - val_loss: 1.4334 - val_accuracy: 0.6610\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 1.0871 - accuracy: 0.7007 - val_loss: 1.4107 - val_accuracy: 0.6660\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 1.0041 - accuracy: 0.7311 - val_loss: 1.3879 - val_accuracy: 0.6890\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.9339 - accuracy: 0.7641 - val_loss: 1.3742 - val_accuracy: 0.7050\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.8735 - accuracy: 0.7829 - val_loss: 1.3920 - val_accuracy: 0.6990\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.8194 - accuracy: 0.7933 - val_loss: 1.3791 - val_accuracy: 0.7120\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.7745 - accuracy: 0.8022 - val_loss: 1.3996 - val_accuracy: 0.7060\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.7302 - accuracy: 0.8089 - val_loss: 1.4224 - val_accuracy: 0.7100\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.6935 - accuracy: 0.8191 - val_loss: 1.4381 - val_accuracy: 0.7080\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.6598 - accuracy: 0.8264 - val_loss: 1.4604 - val_accuracy: 0.7120\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.6276 - accuracy: 0.8336 - val_loss: 1.4597 - val_accuracy: 0.7140\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 0.6003 - accuracy: 0.8395 - val_loss: 1.5373 - val_accuracy: 0.7060\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.5743 - accuracy: 0.8430 - val_loss: 1.5628 - val_accuracy: 0.7040\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.5501 - accuracy: 0.8464 - val_loss: 1.5553 - val_accuracy: 0.6990\n",
      "2246/2246 [==============================] - 0s 140us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=256,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6121739126801597, 0.6914514899253845]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "7982/7982 [==============================] - 1s 177us/step - loss: 2.5704 - accuracy: 0.5530 - val_loss: 1.8183 - val_accuracy: 0.6400\n",
      "Epoch 2/10\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 1.4808 - accuracy: 0.7083 - val_loss: 1.3504 - val_accuracy: 0.7160\n",
      "Epoch 3/10\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 1.0821 - accuracy: 0.7809 - val_loss: 1.1377 - val_accuracy: 0.7710\n",
      "Epoch 4/10\n",
      "7982/7982 [==============================] - 1s 121us/step - loss: 0.8457 - accuracy: 0.8299 - val_loss: 1.0158 - val_accuracy: 0.7990\n",
      "Epoch 5/10\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.6807 - accuracy: 0.8680 - val_loss: 0.9395 - val_accuracy: 0.8090\n",
      "Epoch 6/10\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.5556 - accuracy: 0.8923 - val_loss: 0.8921 - val_accuracy: 0.8180\n",
      "Epoch 7/10\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.4577 - accuracy: 0.9088 - val_loss: 0.8501 - val_accuracy: 0.8250\n",
      "Epoch 8/10\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.3811 - accuracy: 0.9223 - val_loss: 0.8338 - val_accuracy: 0.8190\n",
      "Epoch 9/10\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.3198 - accuracy: 0.9341 - val_loss: 0.8241 - val_accuracy: 0.8230\n",
      "Epoch 10/10\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.2726 - accuracy: 0.9417 - val_loss: 0.8146 - val_accuracy: 0.8290\n",
      "2246/2246 [==============================] - 0s 88us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=10,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8944515375186584, 0.799198567867279]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
